{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07852139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "response = requests.get('http://atlas.obs-hp.fr/sophie/sophie.cgi?n=sophies&a=htab&ob=ra,seq&c=o&o=51%20peg')\n",
    "\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66d73adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "dates:  183\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "# Obtener el html\n",
    "\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "xpath_title = '//table[@class=\"datatable\"]/tbody/tr/td[7]/text()'\n",
    "\n",
    "query = soup.select('table[class=\"datatable\"] tbody tr')\n",
    "\n",
    "print(len(query))\n",
    "#print(query[1].select('td')[6])\n",
    "dates = []\n",
    "for i in range(0, len(query)):\n",
    "    #print(query[i].select('td')[6].text)\n",
    "    dates.append(query[i].select('td')[6].text)\n",
    "print('dates: ', len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456fe760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "# Obtener el html\n",
    "\n",
    "soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "xpath_title = '//table[@class=\"datatable\"]/thead/tr/th/a/text()'\n",
    "\n",
    "\n",
    "query = soup.select('table[class=\"datatable\"] thead th')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c61043",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85c5c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['objname',\n",
       "  'RA (J2000) Dec',\n",
       "  'S',\n",
       "  'E',\n",
       "  'seq',\n",
       "  'slen',\n",
       "  'date',\n",
       "  'mode',\n",
       "  'fiber_b',\n",
       "  'exptime',\n",
       "  'sn26',\n",
       "  'view_spec',\n",
       "  'view_head',\n",
       "  'get_spec',\n",
       "  'get_e2ds',\n",
       "  'customize',\n",
       "  'search_ccf'],\n",
       " {'date': 6, 'fiber_b': 8, 'sn26': 10, 'view_head': 12, 'search_ccf': 16})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query = soup.select('table[class=\"datatable\"] thead tr th a')\n",
    "#header = [querys.text for querys in query]\n",
    "\n",
    "\n",
    "def _get_headers():\n",
    "    row_header = soup.select('table[class=\"datatable\"] thead tr th a')\n",
    "    # table_body's header\n",
    "    headers = [header.text for header in row_header]\n",
    "\n",
    "    # List of data I want to get\n",
    "    data_list = ['date', 'fiber_b', 'sn26', 'view_head', 'search_ccf']  \n",
    "    position = []\n",
    "    for i in range(0, len(headers)):\n",
    "        for data in data_list:\n",
    "            if headers[i] == data:\n",
    "                position.append(i)\n",
    "\n",
    "    columns = {}\n",
    "    for i in range(0, len(data_list)):\n",
    "        columns[data_list[i]] = position[i]\n",
    "    return headers, columns\n",
    "_get_headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f46aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'date': 6, 'fiber_b': 8, 'sn26': 10, 'view_spec': 11, 'search_ccf': 16}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = soup.select('table[class=\"datatable\"] thead th')\n",
    "print(len(query))\n",
    "\n",
    "header = []\n",
    "for i in range(0,len(query)):\n",
    "    header.append(query[i].text)\n",
    "\n",
    "lista = ['date', 'fiber_b', 'sn26', 'view_spec', 'search_ccf']    \n",
    "posicion = []\n",
    "for i in range(0,len(header)):\n",
    "    for j in range(0,len(lista)):\n",
    "        if header[i] == lista[j]:\n",
    "            posicion.append(i)\n",
    "\n",
    "diccionario ={}\n",
    "for i in range(0, len(lista)):\n",
    "    diccionario[lista[i]]=posicion[i]\n",
    "diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c0dbc",
   "metadata": {},
   "source": [
    "# Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f77c9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"sophie.cgi?n=sophiecc&amp;a=hexp&amp;fql=[seq =825680]\">search_CCF</a>\n"
     ]
    }
   ],
   "source": [
    "query = soup.select('table[class=\"datatable\"] tbody tr')\n",
    "\n",
    "\n",
    "print(query[3].select('td')[16].select('a')[0])\n",
    "#print(query[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "374ba586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo de ejemplo platzi\n",
    "def article_links(self):\n",
    "    link_list = []\n",
    "    for link in self._select(self._queries['homepage_article_links']):\n",
    "        if link and link.has_attr('href'):\n",
    "            link_list.append(link)\n",
    "\n",
    "    return set(link['href'] for link in link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e84b1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column():    \n",
    "    query = soup.select('table[class=\"datatable\"] tbody tr')\n",
    "    \n",
    "    select_a = []\n",
    "    for i in range(0, len(query)):\n",
    "        data = query[i].select('td')[16].select('a')\n",
    "        \n",
    "        select_a.append(data)\n",
    "    \n",
    "    link_list = []\n",
    "    none_url = []\n",
    "    for index, link in enumerate(select_a):\n",
    "        if len(link) == 0:\n",
    "            none_url.append(index)\n",
    "        elif link[0] and link[0].has_attr('href'):\n",
    "            link_list.append(link)\n",
    "\n",
    "            \n",
    "    return list(link[0]['href'] for link in link_list), none_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "646dd53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "[11, 12, 13, 14, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "a, none_url_list = column()\n",
    "print(len(a))\n",
    "print(none_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8d044",
   "metadata": {},
   "source": [
    "# Arreglar links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ff0c1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _obtein_data(rows, column_name, none_url_list):\n",
    "\n",
    "    results = []\n",
    "    for i in range(0, len(rows)):\n",
    "        data = rows[i].select('td')[column_name].text\n",
    "        if len(data) !=0:\n",
    "            results.append(data)\n",
    "        elif len(data) == 0:\n",
    "            results.append('')\n",
    "    \n",
    "    results_clean = np.delete(results, none_url_list).tolist()\n",
    "    return results_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "046bd3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    }
   ],
   "source": [
    "rows = soup.select('table[class=\"datatable\"] tbody tr')\n",
    "print( len(_obtein_data(rows, 6, [11, 12, 13, 14, 15, 16, 17])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1b545255",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-182-0aef23b9169b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-182-0aef23b9169b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    borrar.(lambda x: x.replace(',',':'))\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "borrar = [1,3,5]\n",
    "borrar.(lambda x: x.replace(',',':'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0ae95a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ricky', 'David', 'Jose', 'Jose', 'Jose']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "lista_nombres = ['Ricky', 'Alvaro', 'David', 'Jacinto', 'Jose', 'Ricky', 'Jose', 'Jose']\n",
    "borrar = [1,3,5]\n",
    "np.delete(lista_nombres, borrar).tolist()\n",
    "# Returns: ['l', '42', 'u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46a72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
